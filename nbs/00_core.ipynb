{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Utility for automating backups of a specific file or directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Backups\n",
    "\n",
    "We want a script to back up a specific file/folder over different intervals. Specifically, it should\n",
    "\n",
    "- Copy to some destination dir every hour (e.g. a different drive)\n",
    "- Keep the last 5, and one every day, week and month (for example)\n",
    "\n",
    "We can then rsync the destination dir to keep a remote backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import shutil, os, time, pprint, logging\n",
    "from pathlib import Path\n",
    "from fastcore.script import call_parse\n",
    "from fastcore.xtras import globtastic\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p demo_src\n",
    "!mkdir -p demo_dst\n",
    "!rm -rf demo_dst/*\n",
    "!rm -rf demo_src/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"content\" > \"demo_src/test_text.txt\"\n",
    "!echo \"## content\" > \"demo_src/test_two.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan has two main steps:\n",
    "\n",
    "- Create a new backup\n",
    "- Clean up any old backups that are no longer needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For step 1 we want to go file by file in case of errors, and support a matching pattern for what to include. So, take 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['demo_src/test_two.md']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globtastic(\"demo_src\", file_glob=\"*.md\") # Finding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_backup(src, dest_dir, pattern=None, skip_pattern=None, dry_run=False):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    src_path = Path(src)\n",
    "    dest_path = Path(dest_dir) / timestamp\n",
    "    if not dry_run: dest_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if src_path.is_file():\n",
    "        files_to_copy = [src_path]\n",
    "    else:\n",
    "        if pattern or skip_pattern:\n",
    "            files_to_copy = globtastic(src_path, file_glob=pattern, skip_file_glob=skip_pattern)\n",
    "            files_to_copy = [Path(f) for f in files_to_copy]\n",
    "        else: files_to_copy = src_path.rglob('*')\n",
    "    \n",
    "    for file in files_to_copy:\n",
    "        if file.is_file():\n",
    "            rel_path = file.relative_to(src_path)\n",
    "            dest_file = dest_path / rel_path\n",
    "            if not dry_run: dest_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                if dry_run: print(f'Copy from {file} to {dest_file}')\n",
    "                else: shutil.copy2(file, dest_file)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to copy {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241127_144821\r\n"
     ]
    }
   ],
   "source": [
    "create_backup('demo_src', 'demo_dst')\n",
    "!ls demo_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_text.txt  test_two.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls demo_dst/20241127_144821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy from demo_src/test_text.txt to demo_dst/20241127_144834\n"
     ]
    }
   ],
   "source": [
    "# Test single file\n",
    "create_backup('demo_src/test_text.txt', 'demo_dst', dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy from demo_src/test_two.md to demo_dst/20241127_144846/test_two.md\n"
     ]
    }
   ],
   "source": [
    "# Test pattern\n",
    "create_backup('demo_src', 'demo_dst', pattern='*.md', dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy from demo_src/test_text.txt to demo_dst/20241127_144851/test_text.txt\n"
     ]
    }
   ],
   "source": [
    "# Test skip_pattern\n",
    "create_backup('demo_src', 'demo_dst', skip_pattern='*.md', dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The harder part is the cleanup. Let's start by generating some dates to test with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20240819_144856', '20240819_154856', '20240819_164856', '20240819_174856', '20240819_184856'] ['20241127_094856', '20241127_104856', '20241127_114856', '20241127_124856', '20241127_134856']\n"
     ]
    }
   ],
   "source": [
    "def generate_test_dates(num_dates, base_date):\n",
    "    return [(base_date + timedelta(hours=i)).strftime(\"%Y%m%d_%H%M%S\") for i in range(num_dates)]\n",
    "test_dates = generate_test_dates(2400, datetime.now() - timedelta(days=100))\n",
    "print(test_dates[:5], test_dates[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240928_154856', '20240928_164856', '20240928_174856']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can I get all dates < 2 months old?\n",
    "[d for d in test_dates if (datetime.now() - datetime.strptime(d, '%Y%m%d_%H%M%S')).days < 60][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to grab the most recent 5, and then the oldest below some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def clean_dates(dates, now=None, max_ages=(2, 14, 60)):\n",
    "    now = now or datetime.now()\n",
    "    clean = []\n",
    "    dates.sort()\n",
    "    \n",
    "    for max_age in max_ages:\n",
    "        lt_max = [d for d in dates if (now - datetime.strptime(d, '%Y%m%d_%H%M%S')).days < max_age]\n",
    "        if lt_max: clean.append(lt_max[0])\n",
    "\n",
    "    clean.extend(dates[-5:])  # Keep the newest 5\n",
    "    return sorted(set(clean))  # Remove duplicates and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240928_154856',\n",
       " '20241113_154856',\n",
       " '20241125_154856',\n",
       " '20241127_094856',\n",
       " '20241127_104856',\n",
       " '20241127_114856',\n",
       " '20241127_124856',\n",
       " '20241127_134856']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dates(test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want code that starts with the same test dates etc as above, but then simulates time passing by adding an hour to 'now' and a date to test dates every step then printing out a (prettified) version of clean_dates to check it's doing as I expect over a simulated month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize\n",
    "# now = datetime.now()\n",
    "# test_dates = generate_test_dates(2400, now - timedelta(days=100))\n",
    "\n",
    "# # Simulate time passing\n",
    "# for _ in range(30 * 24):  # Simulate a month (30 days * 24 hours)\n",
    "#     now += timedelta(hours=1)\n",
    "#     test_dates.append(now.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "#     test_dates = clean_dates(test_dates, now)  # Clean up old dates\n",
    "#     if _ % 24 == 0:  # Print once a day\n",
    "#         print(f\"\\nDay {_ // 24 + 1}:\")\n",
    "#         pprint.pprint(test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Yay, it looks to be doing mostly what I want! I can collapse the output, if you're viewing this in a notebook my apologies :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning it into a script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that those two pieces of functionality seem to be working, we can wrap this up as a script using fastcore's call_parse, have it run the backup, clean up old files, and log any errors or messages to backup.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def run_backup(\n",
    "    src:str, # The source to be backed up\n",
    "    dest:str, # The destination directory\n",
    "    max_ages:str=\"2,14,60\", # The max age(s) in days for the different backups\n",
    "    log_file:str='backup.log',\n",
    "    pattern:str=None, # Globtastic file_glob pattern\n",
    "    skip_pattern:str=None, # Globtastic skip_file_glob pattern\n",
    "    dry_run:bool=False # Dry run?\n",
    "):\n",
    "    \"Run backup and cleanup old files\"\n",
    "    \n",
    "    # Set up logging\n",
    "    logging.basicConfig(filename=log_file, level=logging.DEBUG,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    try:\n",
    "        create_backup(src, dest, pattern=pattern, skip_pattern=skip_pattern, dry_run=dry_run)\n",
    "        logging.info(f\"Backup created: {src} -> {dest}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Backup failed: {str(e)}\", exc_info=True)\n",
    "    finally:\n",
    "        max_ages = [int(age.strip()) for age in max_ages.split(',')]\n",
    "        backups = [d.name for d in Path(dest).iterdir() if d.is_dir()]\n",
    "        to_keep = clean_dates(backups, max_ages=max_ages)\n",
    "        for backup in backups:\n",
    "            if backup not in to_keep:\n",
    "                try:\n",
    "                    if dry_run:print('Remove', Path(dest) / backup)\n",
    "                    else: shutil.rmtree(Path(dest) / backup)\n",
    "                    logging.info(f\"Removed old backup: {backup}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Removing old backup failed: {str(e)}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_text.txt  test_two.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls demo_src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r demo_dst/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241127_145001\r\n"
     ]
    }
   ],
   "source": [
    "run_backup('demo_src', 'demo_dst')\n",
    "!ls demo_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_text.txt  test_two.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls demo_dst/20241127_145001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r demo_dst/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy from demo_src/test_text.txt to demo_dst/20241127_145017/test_text.txt\n"
     ]
    }
   ],
   "source": [
    "run_backup('demo_src', 'demo_dst', skip_pattern=\"*.md\", dry_run=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
